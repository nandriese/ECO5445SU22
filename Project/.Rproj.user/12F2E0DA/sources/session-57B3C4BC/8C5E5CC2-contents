---
title: "Assignment07"
author: "Guillermo"
date: '2022-07-28'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(readr)
library(gvlma)
library(MASS)
library(leaps)
library(car)
library(gamlr)
library(Metrics)
```

1. This time, I want you to separate your data into testing and training. For this exercise, randomly extract 100 for testing different models, and save the other 900 for training your models.

```{r}
housing <- read_csv("~/GitHub/ECO5445SU22/Assignment07/data/prop_prices_reduced.csv", col_names = TRUE)

housing$sale_def <- housing$sale_def/1000
housing$dist_lakes <- housing$dist_lakes/mean(housing$dist_lakes)

attach(housing)

set.seed(1234)
Data_subset <- sample(nrow(housing), .9*nrow(housing))

housing.training <- housing[Data_subset,]
housing.validate <- housing[-Data_subset,]
```


2. Run your final model you had in the previous assignment to the training data

```{r}
newfit2 <-  lm(log(sale_def) ~ bed + bath + area_heated + area + dist_cbd + log(dist_lakes) + pool, data = housing.training)

summary(newfit2)
```


3. With the same model in part 2, run the standard LASSO regression model on the training data.

```{r}
housing.x <- housing.training[-c(1)]
housing.y <- housing.training[c(1)]
housing.x$dist_lakes <- log(housing.x$dist_lakes)

housing.x <- data.matrix(housing.x)
housing.y <- data.matrix(housing.y)

spender <- gamlr(housing.x, log(housing.y), verb=TRUE, family = "gaussian", standardize = TRUE)

summary(spender)
plot(spender, ylim = c(-.05, .15), xlim = c(-7,-1)) 
```

4. Now using the same model in part 2, run a 10-fold cross-validated LASSO on the training data

- Below we create the cross validation Lasso model

```{r}
cv.spender <- cv.gamlr(housing.x, log(housing.y),
	family="gaussian", verb=TRUE, standardize=TRUE, nfold = 10)

```

- Below we plot the cross validation 

```{r}
par(mfrow=c(1,2))
plot(cv.spender)
plot(cv.spender$gamlr) ## cv.gamlr has included a gamlr object into cv.nhlreg

```


5. Lastly, using the testing data, I want you to calculate the RMSE for each of the lambda's selection methods discussed (AIC, BIC, AICc, cv.min, cv.1se) and the the model in part 2. Which method performed the best in prediction the home price?

```{r}
Predicted <- predict(newfit2, housing.validate)
Actuals <- log(housing.validate$sale_def)
OG.rmse <- rmse(Actuals, Predicted)

# below we need to log the distance to lakes to fit the gamlr models. 
housing.validate$dist_lakes <- log(housing.validate$dist_lakes)

LassoPredict1 <- predict(spender, housing.validate[-c(1)], select =which.min(AICc(spender)))
LassoPredict1 <- as.matrix(LassoPredict1)
Lasso.aiccrmse <- rmse(Actuals, LassoPredict1)

LassoPredict2 <- predict(spender, housing.validate[-c(1)], select =which.min(AIC(spender)))
LassoPredict2 <- as.matrix(LassoPredict2)
Lasso.aicrmse <- rmse(Actuals, LassoPredict2)

LassoPredict3 <- predict(spender, housing.validate[-c(1)], select =which.min(BIC(spender)))
LassoPredict3 <- as.matrix(LassoPredict3)
Lasso.bicrmse <- rmse(Actuals, LassoPredict3)

CVPredict1 <- predict(cv.spender, housing.validate[-c(1)], select ="min")
CVPredict1 <- as.matrix(CVPredict1)
CV.minrmse <- rmse(Actuals, CVPredict1)

CVPredict2 <- predict(cv.spender, housing.validate[-c(1)], select ="1se")
CVPredict2 <- as.matrix(CVPredict2)
CV.1sermse <- rmse(Actuals, CVPredict2)


#here we undo the distance to lakes in case you need to run the chunk again. 
housing.validate <- housing[-Data_subset,]

```


```{r}
OG.rmse
Lasso.aiccrmse
Lasso.aicrmse
Lasso.bicrmse
CV.minrmse
CV.1sermse
```
- After looking at the RMSE of each model. We see that the lasso AICC, AIC, BIC, and cross fold validation min are all exactly the same at .2725 . From there the original regression sits at .2733, finally we have the cross fold validation 1se model at .2756 is the highest error. I would choose the cross fold validation min for the best predictions, otherwise all models are nearly identical. 

